{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eG4viXQp3Tf"
      },
      "source": [
        "##Overview\n",
        "At the core of CNNs are filters (aka weights, kernels, etc.) which convolve (slide) across our input to extract relevant features. The filters are initialized randomly but learn to act as feature extractors via parameter sharing.\n",
        "\n",
        "###Objective:\n",
        "* Extract meaningful spatial substructure from encoded data.\n",
        "\n",
        "###Advantages:\n",
        "* Small number of weights (shared)\n",
        "* Parallelizable\n",
        "* Detects spatial substrcutures (feature extractors)\n",
        "* Interpretability via filters\n",
        "* Can be used for processing in images, text, time-series, etc.\n",
        "\n",
        "###Disadvantages:\n",
        "* Many hyperparameters (kernel size, strides, etc.) to tune.\n",
        "\n",
        "###Miscellaneous:\n",
        "* Lot's of deep CNN architectures constantly updated for SOTA performance.\n",
        "* Very popular feature extractor that acts as a foundation for many architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQcUpHR6rULa"
      },
      "source": [
        "##Set up\n",
        "Let's set our seed and device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8r93d5INpjuR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ibA2mqSiprVF"
      },
      "outputs": [],
      "source": [
        "SEED = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2rWPiTMWpsyg"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x4ZbcSt1puvB"
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds(seed=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPWjW70Epwzu",
        "outputId": "0b5ad540-f8d0-4105-dab4-ae4df3df6673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhHaCprOrXch"
      },
      "source": [
        "##Load data\n",
        "We will download the AG News dataset, which consists of 120K text samples from 4 unique classes (Business, Sci/Tech, Sports, World)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p0cc_wcRrf97",
        "outputId": "10d732b2-2297-439f-cd27-aaf8023177f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/sumitraju/data-science/main/cnn_spatial_substructure_info/data/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeNBIPgvrk1R"
      },
      "source": [
        "##Preprocessing\n",
        "We're going to clean up our input data first by doing operations such as lower text, removing stop (filler) words, filters using regular expressions, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g84oZLPprpln"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIxH83Nmrro4",
        "outputId": "4fcdcae1-575b-45f0-e592-eaac36552d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\raju_\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nXOZ_gAZrtWT"
      },
      "outputs": [],
      "source": [
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in parenthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)  # separate punctuation tied to words\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text)  # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tl2CDJrCrvP-",
        "outputId": "d9cc7c80-6864-4cc9-e2c5-31b62112bbde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQpMe9_ZrxCX",
        "outputId": "e37dfeef-3837-4c93-e657-8a614b7c4161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ]
        }
      ],
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmpIp-YnrzdT"
      },
      "source": [
        "##Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fo3xyy-Zry3d"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZQP6bNLCr4R_"
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2DsXqd7Sr5sP"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_uHPFbnDr_eJ"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfsW7DNxsB3X",
        "outputId": "2c31b05c-57f8-4d6b-f3f0-e12294677559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks → World\n"
          ]
        }
      ],
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fClqsHRrsEc6"
      },
      "source": [
        "##Label encoding\n",
        "Next we'll define a LabelEncoder to encode our text labels into unique indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "w1orkF6KsHrF"
      },
      "outputs": [],
      "source": [
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QAF_pUWCsKQn"
      },
      "outputs": [],
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros((len(y)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9RdVd_NsMwy",
        "outputId": "a31b231e-496b-484a-b926-fdc164d8dfd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaWn7iLasO0M",
        "outputId": "67187dda-696c-46be-f054-a3c717bd4479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ]
        }
      ],
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB-MOaiisQxg",
        "outputId": "47c8d072-a3e2-4dec-c418-3a08fae66f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ]
        }
      ],
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR3OIY-KsV8g"
      },
      "source": [
        "##Tokenizer\n",
        "Our input data is text and we can't feed it directly to our models. So, we'll define a Tokenizer to convert our text input data into token indices. This means that every token (we can decide what a token is char, word, sub-word, etc.) is mapped to a unique index which allows us to represent our text as an array of indices.##Tokenizer\n",
        "Our input data is text and we can't feed it directly to our models. So, we'll define a Tokenizer to convert our text input data into token indices. This means that every token (we can decide what a token is char, word, sub-word, etc.) is mapped to a unique index which allows us to represent our text as an array of indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ro4kTEK8sS7T"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5XyVkvhdsa-5"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = \"\" if self.char_level else \" \"\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS7JfBBYsevd"
      },
      "source": [
        "We're going to restrict the number of tokens in our Tokenizer to the top 500 most frequent tokens (stop words already removed) because the full vocabulary size (~30K) is too large to run on Google Colab notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8iKQZVBsdZ7",
        "outputId": "1c4e69ed-55a0-41b4-a874-24769322dbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6QnnF7fskVd",
        "outputId": "56b86545-6701-41d3-8596-cd35d2261042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 166\n"
          ]
        }
      ],
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWTzZzC9smN9",
        "outputId": "30af8250-397d-4514-e05f-cf2a854ab975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → china <UNK> north korea nuclear talks\n",
            "  (tokenized) → [ 16   1 285 142 114  24]\n"
          ]
        }
      ],
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR6GisJvspM1"
      },
      "source": [
        "##One-hot encoding\n",
        "One-hot encoding creates a binary column for each unique value for the feature we're trying to map. All of the values in each token's array will be 0 except at the index that this specific token is represented by.\n",
        "\n",
        "There are 5 words in the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC2SJxQwsscA",
        "outputId": "74cb0e18-7ae1-497b-8b4e-58ec30a4734f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': 0, 'e': 1, 'i': 2, 'o': 3, 'u': 4}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{\n",
        "    \"a\": 0,\n",
        "    \"e\": 1,\n",
        "    \"i\": 2,\n",
        "    \"o\": 3,\n",
        "    \"u\": 4\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cow5j5bUtPJz"
      },
      "source": [
        "One-hot encoding allows us to represent our data in a way that our models can process the data and isn't biased by the actual value of the token (ex. if your labels were actual numbers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Z__9YqAZtLy-"
      },
      "outputs": [],
      "source": [
        "def to_categorical(seq, num_classes):\n",
        "    \"\"\"One-hot encode a sequence of tokens.\"\"\"\n",
        "    one_hot = np.zeros((len(seq), num_classes))\n",
        "    for i, item in enumerate(seq):\n",
        "        one_hot[i, item] = 1.\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEVsfzkptSPa",
        "outputId": "641b6038-6901-48f1-debe-d51be4339516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 16   1 285 142 114  24]\n",
            "6\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(6, 500)\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding\n",
        "print (X_train[0])\n",
        "print (len(X_train[0]))\n",
        "cat = to_categorical(seq=X_train[0], num_classes=len(tokenizer))\n",
        "print (cat)\n",
        "print (cat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3xbwDjv2tXrp"
      },
      "outputs": [],
      "source": [
        "# Convert tokens to one-hot\n",
        "vocab_size = len(tokenizer)\n",
        "X_train = [to_categorical(seq, num_classes=vocab_size) for seq in X_train]\n",
        "X_val = [to_categorical(seq, num_classes=vocab_size) for seq in X_val]\n",
        "X_test = [to_categorical(seq, num_classes=vocab_size) for seq in X_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv6UCeXtta1T"
      },
      "source": [
        "##Padding\n",
        "Our inputs are all of varying length but we need each batch to be uniformly shaped. Therefore, we will use padding to make all the inputs in the batch the same length. Our padding index will be 0 (note that this is consistent with the <PAD> token defined in our Tokenizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P54z_MGftdNb"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    num_classes = sequences[0].shape[-1]\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6REZK5x-tfku",
        "outputId": "5ba4d2e6-7d2a-42ac-c093-7d4a685d5c9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 500) (5, 500) (6, 500)\n",
            "(3, 6, 500)\n"
          ]
        }
      ],
      "source": [
        "# 3D sequences\n",
        "print (X_train[0].shape, X_train[1].shape, X_train[2].shape)\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDv21bjKthzJ"
      },
      "source": [
        "##Dataset\n",
        "We're going to create Datasets and DataLoaders to be able to efficiently create batches with our data splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WYD3ULWctkFQ"
      },
      "outputs": [],
      "source": [
        "FILTER_SIZE = 1 # unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6dK5Fu3ktmSi"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch)\n",
        "        X = batch[:, 0]\n",
        "        y = batch[:, 1]\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.FloatTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxo9Be43toCi",
        "outputId": "ef98f7d4-f794-4bc2-d9d0-64801bc4bd7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "  y: 1\n"
          ]
        }
      ],
      "source": [
        "# Create datasets for embedding\n",
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=FILTER_SIZE)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {test_dataset[0][0]}\\n\"\n",
        "    f\"  y: {test_dataset[0][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN48Di7Itpyk",
        "outputId": "00675dfe-e322-48c2-afba-5f8580bee1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [64, 14, 500]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "  y: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/2695874199.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "batch_X, batch_y = next(iter(test_dataloader))\n",
        "print (\"Sample batch:\\n\"\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {batch_X[0]}\\n\"\n",
        "    f\"  y: {batch_y[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fAUr6WBtr_C"
      },
      "source": [
        "##CNN\n",
        "We're going to learn about CNNs by applying them on 1D text data.\n",
        "\n",
        "##Inputs\n",
        "In the dummy example below, our inputs are composed of character tokens that are one-hot encoded. We have a batch of N samples, where each sample has 8 characters and each character is represented by an array of 10 values (vocab size=10). This gives our inputs the size (N, 8, 10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "h6lBUFpCtufS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gKq9dkZtwAu",
        "outputId": "e5aec126-f774-4ef4-a380-687cab093a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: torch.Size([64, 8, 10])\n",
            "X: torch.Size([64, 10, 8])\n"
          ]
        }
      ],
      "source": [
        "# Assume all our inputs are padded to have the same # of words\n",
        "batch_size = 64\n",
        "max_seq_len = 8 # words per input\n",
        "vocab_size = 10 # one hot size\n",
        "x = torch.randn(batch_size, max_seq_len, vocab_size)\n",
        "print(f\"X: {x.shape}\")\n",
        "x = x.transpose(1, 2)\n",
        "print(f\"X: {x.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyTy_4Aytyto"
      },
      "source": [
        "##Filters\n",
        "At the core of CNNs are filters (aka weights, kernels, etc.) which convolve (slide) across our input to extract relevant features. The filters are initialized randomly but learn to act as feature extractors via parameter sharing.\n",
        "\n",
        "We can see convolution in the diagram below where we simplified the filters and inputs to be 2D for ease of visualization. Also note that the values are 0/1s but in reality they can be any floating point value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHzt5iV9t57O",
        "outputId": "db67227f-217f-4574-ecb7-cf68f190eca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ]
        }
      ],
      "source": [
        "# Convolutional filters (VALID padding)\n",
        "vocab_size = 10 # one hot size\n",
        "num_filters = 50 # num filters\n",
        "filter_size = 3 # filters are 3X3\n",
        "stride = 1\n",
        "padding = 0 # valid padding (no padding)\n",
        "conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,\n",
        "                  kernel_size=filter_size, stride=stride,\n",
        "                  padding=padding, padding_mode=\"zeros\")\n",
        "print(\"conv: {}\".format(conv1.weight.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PWqzqMtt7-E",
        "outputId": "2524b5b2-af77-47ef-9b88-ffb4dacc5ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ]
        }
      ],
      "source": [
        "# Forward pass\n",
        "z = conv1(x)\n",
        "print (f\"z: {z.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsgo33KPt_XA",
        "outputId": "d637f0e6-938f-436c-a64c-218b0c9520a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ]
        }
      ],
      "source": [
        "# Convolutional filters (SAME padding)\n",
        "vocab_size = 10 # one hot size\n",
        "num_filters = 50 # num filters\n",
        "filter_size = 3 # filters are 3X3\n",
        "stride = 1\n",
        "conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,\n",
        "                 kernel_size=filter_size, stride=stride)\n",
        "print(\"conv: {}\".format(conv.weight.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5rAq40BuBga",
        "outputId": "7a600b39-18ba-4580-f899-f3f422450c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "padding: (1, 1)\n"
          ]
        }
      ],
      "source": [
        "# `SAME` padding\n",
        "padding_left = int((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2)\n",
        "padding_right = int(math.ceil((conv.stride[0]*(max_seq_len-1) - max_seq_len + filter_size)/2))\n",
        "print (f\"padding: {(padding_left, padding_right)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKrl01OQuDg2",
        "outputId": "1126c956-cb48-414d-8b04-223f6014f399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 8])\n"
          ]
        }
      ],
      "source": [
        "# Forward pass\n",
        "z = conv(F.pad(x, (padding_left, padding_right)))\n",
        "print (f\"z: {z.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hr1QfD4uFkK"
      },
      "source": [
        "##Pooling\n",
        "The result of convolving filters on an input is a feature map. Due to the nature of convolution and overlaps, our feature map will have lots of redundant information. Pooling is a way to summarize a high-dimensional feature map into a lower dimensional one for simplified downstream computation. The pooling operation can be the max value, average, etc. in a certain receptive field. Below is an example of pooling where the outputs from a conv layer are 4X4 and we're going to apply max pool filters of size 2X2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sESg395xuIdV",
        "outputId": "ee3dd3f2-6cef-4fdf-dbc8-66fef8dbf409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 50, 1])\n"
          ]
        }
      ],
      "source": [
        "# Max pooling\n",
        "pool_output = F.max_pool1d(z, z.size(2))\n",
        "print(\"Size: {}\".format(pool_output.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4vMi2tRuKY_"
      },
      "source": [
        "##Batch normalization\n",
        "The last topic we'll cover before constructing our model is batch normalization. It's an operation that will standardize (mean=0, std=1) the activations from the previous layer. Recall that we used to standardize our inputs in previous notebooks so our model can optimize quickly with larger learning rates. It's the same concept here but we continue to maintain standardized values throughout the repeated forward passes to further aid optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63HgouvNuMix",
        "outputId": "5de0c2e8-fbe6-413b-e2f0-a889fb457490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ]
        }
      ],
      "source": [
        "# Batch normalization\n",
        "batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "z = batch_norm(conv(x)) # applied to activations (after conv layer & before pooling)\n",
        "print (f\"z: {z.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ZXErUPuOFM",
        "outputId": "3319c2b4-2e58-4cd1-b1e6-92fdabab49aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean: -0.01, std: 0.57\n"
          ]
        }
      ],
      "source": [
        "# Mean and std before batchnorm\n",
        "print (f\"mean: {torch.mean(conv(x)):.2f}, std: {torch.std(conv(x)):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TLlxtOtuQB3",
        "outputId": "993a35e6-2d36-4cc8-807f-744cfac8a246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean: 0.00, std: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Mean and std after batchnorm\n",
        "print (f\"mean: {torch.mean(z):.2f}, std: {torch.std(z):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWbzDQSSuS_x"
      },
      "source": [
        "##Modeling\n",
        "###Model\n",
        "Let's visualize the model's forward pass.\n",
        "\n",
        "We'll first tokenize our inputs (batch_size, max_seq_len).\n",
        "Then we'll one-hot encode our tokenized inputs (batch_size, max_seq_len, vocab_size).\n",
        "We'll apply convolution via filters (filter_size, vocab_size, num_filters) followed by batch normalization. Our filters act as character level n-gram detectors.\n",
        "We'll apply 1D global max pooling which will extract the most relevant information from the feature maps for making the decision.\n",
        "We feed the pool outputs to a fully-connected (FC) layer (with dropout).\n",
        "We use one more FC layer with softmax to derive class probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "itje8QVIuWTP"
      },
      "outputs": [],
      "source": [
        "NUM_FILTERS = 50\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cAhz3B5RuXua"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\n",
        "                 hidden_dim, dropout_p, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional filters\n",
        "        self.filter_size = filter_size\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=vocab_size, out_channels=num_filters,\n",
        "            kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\")\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "\n",
        "        # FC layers\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False,):\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        x_in, = inputs\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Padding for `SAME` padding\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # Conv outputs\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "        z = F.max_pool1d(z, z.size(2)).squeeze(2)\n",
        "\n",
        "        # FC layer\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTBcCOrYuZsH",
        "outputId": "c1cd7f62-5853-4d44-9320-a7e3c504c3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2msabWDMuhLG"
      },
      "source": [
        "##Training\n",
        "Let's create the Trainer class that we'll use to facilitate training for our experiments. Notice that we're now moving the train function inside this class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OzpIMPfNujmK"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "KdVjQmAsukww"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 1e-3\n",
        "PATIENCE = 5\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ubVwInDqul-5"
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "JDggSzoGun6Q"
      },
      "outputs": [],
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "57yLasHcupVe"
      },
      "outputs": [],
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "oFz7R6HPuqmu"
      },
      "outputs": [],
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SZ0ubP9utHU",
        "outputId": "e866da9d-9289-42a3-a5ec-99c99dbe09f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/2695874199.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.87321, val_loss: 0.79147, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.78486, val_loss: 0.78464, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.77690, val_loss: 0.78216, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 4 | train_loss: 0.77285, val_loss: 0.78132, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 5 | train_loss: 0.76948, val_loss: 0.78001, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 6 | train_loss: 0.76681, val_loss: 0.77986, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 7 | train_loss: 0.76419, val_loss: 0.77974, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 8 | train_loss: 0.76234, val_loss: 0.77914, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 9 | train_loss: 0.76053, val_loss: 0.77984, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 10 | train_loss: 0.75883, val_loss: 0.77980, lr: 1.00E-03, _patience: 3\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAY7keavux3w"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "VZUCyYQxuxaE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "7HcfQzScu2hm"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Ln-MXYQDu3_4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/2695874199.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/4106836722.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        }
      ],
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "iXaWj-Nwu5TU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7128912711881162,\n",
            "  \"recall\": 0.6933333333333334,\n",
            "  \"f1\": 0.693381426925555,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "c0_UO5bQvDTr"
      },
      "outputs": [],
      "source": [
        "# Save artifacts\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer.save(fp=Path(dir, 'tokenizer.json'))\n",
        "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYtSkaebvFtT"
      },
      "source": [
        "##Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MxT2zZFmvHxP"
      },
      "outputs": [],
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Y8LVr6QRvJpR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, 'tokenizer.json'))\n",
        "model = CNN(\n",
        "    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
        "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "zz2c1FADvLcl"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "UqaIYV9yvM7l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['day new <UNK> stock market go <UNK>']\n"
          ]
        }
      ],
      "source": [
        "# Dataloader\n",
        "text = \"What a day for the new york stock market to go bust!\"\n",
        "sequences = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(sequences))\n",
        "X = [to_categorical(seq, num_classes=len(tokenizer)) for seq in sequences]\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=FILTER_SIZE)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "v6yLVs0FvOih"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/2695874199.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/4106836722.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Business']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "label_encoder.decode(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "mNCxSlzivQiC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Business\": 0.8718783855438232,\n",
            "  \"Sci/Tech\": 0.11128625273704529,\n",
            "  \"World\": 0.013833917677402496,\n",
            "  \"Sports\": 0.0030014696530997753\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Class distributions\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
        "print (json.dumps(prob_dist, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghGUUkXvSVR"
      },
      "source": [
        "##Interpretability\n",
        "We went through all the trouble of padding our inputs before convolution to result in outputs of the same shape as our inputs so we can try to get some interpretability. Since every token is mapped to a convolutional output on which we apply max pooling, we can see which token's output was most influential towards the prediction. We first need to get the conv outputs from our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "CU_yLYusvUhu"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "JsbClSYLvVx1"
      },
      "outputs": [],
      "source": [
        "class InterpretableCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\n",
        "                 hidden_dim, dropout_p, num_classes):\n",
        "        super(InterpretableCNN, self).__init__()\n",
        "\n",
        "        # Convolutional filters\n",
        "        self.filter_size = filter_size\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=vocab_size, out_channels=num_filters,\n",
        "            kernel_size=filter_size, stride=1, padding=0, padding_mode=\"zeros\")\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\n",
        "\n",
        "        # FC layers\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        x_in, = inputs\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Padding for `SAME` padding\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # Conv outputs\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "gij8qnvavXmd"
      },
      "outputs": [],
      "source": [
        "# Initialize\n",
        "interpretable_model = InterpretableCNN(\n",
        "    vocab_size=len(tokenizer), num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "qYvbegymvYyr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load weights (same architecture)\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "interpretable_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "_mH5QrkCvaHo"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "interpretable_trainer = Trainer(model=interpretable_model, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "A0L20FE_vb3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/2695874199.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  batch = np.array(batch)\n",
            "C:\\Users\\raju_\\AppData\\Local\\Temp/ipykernel_8428/4106836722.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  y_prob = F.softmax(z).cpu().numpy()\n"
          ]
        }
      ],
      "source": [
        "# Get conv outputs\n",
        "conv_outputs = interpretable_trainer.predict_step(dataloader)\n",
        "print (conv_outputs.shape) # (num_filters, max_seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "-NGL84QjvdW2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize a bi-gram filter's outputs\n",
        "tokens = tokenizer.sequences_to_texts(sequences)[0].split(\" \")\n",
        "sns.heatmap(conv_outputs, xticklabels=tokens)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "a153b24b7be182ffe9ad34cbe4e2fd92a12934083bdbc60746e07359531e99bd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
